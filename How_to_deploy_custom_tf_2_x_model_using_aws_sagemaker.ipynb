{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "conda_tensorflow_p36",
      "language": "python",
      "name": "conda_tensorflow_p36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "How to deploy custom tf 2.x model using aws sagemaker.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEBKTEyRGL9r"
      },
      "source": [
        "as reference we will follow this tutorial [**Model deployment using AWS SageMaker**](https://medium.com/datadriveninvestor/model-deployment-using-aws-sagemaker-8116adea7184)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYddz7i1Lqle"
      },
      "source": [
        "first of all we will have to train a custom tf 2.x model and generate .h5 or .hdf5 format's weight file that we can deploy using aws sagemaker, my training kernel is private but i trained a model on  [Stanford Sentiment Treebank v2 (SST2)](https://www.kaggle.com/atulanandjha/stanford-sentiment-treebank-v2-sst2)  dataset using this baseline notebook [Understanding cross lingual models](https://www.kaggle.com/mobassir/understanding-cross-lingual-models) i uploaded my models weight file in aws s3 bucket, opened new aws notebook instance and then,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__qsNPmgP4yE"
      },
      "source": [
        "upgrading pip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kch_B4sBvFj",
        "outputId": "c217b870-809e-4c7e-9f06-c0f9d23f0c95"
      },
      "source": [
        "!python -m pip install --upgrade pip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (20.3.3)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9V7rWcSP_2N"
      },
      "source": [
        "installing tf 2.2.0 that i used during training my model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGxH6-pnBvFk",
        "outputId": "b5a2365c-8a52-4e13-bd4c-9523150cce64"
      },
      "source": [
        "!pip3 install tensorflow==2.2.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.2.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (2.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==2.2.0) (0.3.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==2.2.0) (0.34.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==2.2.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==2.2.0) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==2.2.0) (1.31.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==2.2.0) (1.11.2)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==2.2.0) (2.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==2.2.0) (1.18.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==2.2.0) (1.1.2)\n",
            "Requirement already satisfied: scipy==1.4.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==2.2.0) (1.4.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==2.2.0) (3.8.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==2.2.0) (2.10.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==2.2.0) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==2.2.0) (0.11.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==2.2.0) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==2.2.0) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow==2.2.0) (2.2.0)\n",
            "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from protobuf>=3.8.0->tensorflow==2.2.0) (45.2.0.post20200210)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.22.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.3.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.7.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.5)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.5.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.25.10)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdCRQXgzBvFl",
        "outputId": "d80abd33-f879-4929-8c4b-6f7cc58325e3"
      },
      "source": [
        "!pip install tensorflow-gpu==2.2.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.2.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (2.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu==2.2.0) (0.3.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu==2.2.0) (1.31.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu==2.2.0) (2.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu==2.2.0) (1.18.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu==2.2.0) (2.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu==2.2.0) (0.34.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu==2.2.0) (1.11.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu==2.2.0) (1.1.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu==2.2.0) (1.4.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu==2.2.0) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu==2.2.0) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu==2.2.0) (2.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu==2.2.0) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu==2.2.0) (0.11.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu==2.2.0) (3.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu==2.2.0) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorflow-gpu==2.2.0) (1.14.0)\n",
            "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from protobuf>=3.8.0->tensorflow-gpu==2.2.0) (45.2.0.post20200210)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2.0) (3.3.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2.0) (2.22.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2.0) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2.0) (1.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2.0) (0.4.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2.0) (1.24.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2.0) (4.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2.0) (4.5)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2.0) (1.5.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2.0) (0.4.8)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2.0) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2.0) (1.25.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2.0) (2020.6.20)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2.0) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2.0) (2.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzNXgmfSQLYe"
      },
      "source": [
        "installing transformers 2.11.0 that i used during model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toW9i0sOBvFm",
        "outputId": "b07ac8ec-8103-4834-e20f-c273a5a963c0"
      },
      "source": [
        "!pip3 install transformers==2.11.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==2.11.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (2.11.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from transformers==2.11.0) (2020.11.13)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from transformers==2.11.0) (0.7.0)\n",
            "Requirement already satisfied: sentencepiece in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from transformers==2.11.0) (0.1.94)\n",
            "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from transformers==2.11.0) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from transformers==2.11.0) (4.42.1)\n",
            "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from transformers==2.11.0) (1.18.1)\n",
            "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from transformers==2.11.0) (0.8)\n",
            "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from transformers==2.11.0) (20.1)\n",
            "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from transformers==2.11.0) (2.22.0)\n",
            "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from transformers==2.11.0) (3.0.12)\n",
            "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from packaging->transformers==2.11.0) (1.14.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from packaging->transformers==2.11.0) (2.4.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->transformers==2.11.0) (2020.6.20)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->transformers==2.11.0) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->transformers==2.11.0) (2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->transformers==2.11.0) (1.25.10)\n",
            "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from sacremoses->transformers==2.11.0) (7.0)\n",
            "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from sacremoses->transformers==2.11.0) (0.14.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qY9If6CBvFm",
        "outputId": "59606d2e-12fb-4c60-9b99-7692036f4229"
      },
      "source": [
        "!pip install --upgrade sagemaker"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (2.20.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from sagemaker) (20.1)\n",
            "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from sagemaker) (0.2.0)\n",
            "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from sagemaker) (0.1.5)\n",
            "Requirement already satisfied: smdebug-rulesconfig>=1.0.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from sagemaker) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.4.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from sagemaker) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from sagemaker) (1.18.1)\n",
            "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from sagemaker) (19.3.0)\n",
            "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from sagemaker) (3.8.0)\n",
            "Requirement already satisfied: boto3>=1.16.32 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from sagemaker) (1.16.39)\n",
            "Requirement already satisfied: botocore<1.20.0,>=1.19.39 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (1.19.39)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker) (0.3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.39->boto3>=1.16.32->sagemaker) (1.25.10)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.39->boto3>=1.16.32->sagemaker) (2.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from importlib-metadata>=1.4.0->sagemaker) (2.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from packaging>=20.0->sagemaker) (2.4.6)\n",
            "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from packaging>=20.0->sagemaker) (1.14.0)\n",
            "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from protobuf>=3.1->sagemaker) (45.2.0.post20200210)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Df94k2SQZrX"
      },
      "source": [
        "# Cool Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9nlCeOHBvFn",
        "outputId": "0e7bbef6-15bd-4266-9630-7ca761a61fe8"
      },
      "source": [
        "%matplotlib inline\n",
        "import boto3, re, sys, math, json, os, sagemaker, urllib.request\n",
        "from sagemaker import get_execution_role\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sagemaker.tensorflow.serving import Model\n",
        "from sagemaker.predictor import csv_serializer \n",
        "from sagemaker.utils import name_from_base\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input,  Embedding\n",
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "sess = sagemaker.Session()\n",
        "\n",
        "role = get_execution_role()\n",
        "print(role) # This is the role that SageMaker would use to leverage AWS resources (S3, CloudWatch) on your behalf\n",
        "\n",
        "prefix = 'xlmrlarge/' #Replace with the prefix under which you want to store the data if needed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "arn:aws:iam::006159542779:role/service-role/AmazonSageMaker-ExecutionRole-20201216T154428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy_xjHJ5BvFn",
        "outputId": "b432f36f-9f70-4896-95a5-1008c85eceeb"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro7QNw0PBvFo",
        "outputId": "682eb893-9569-4e8a-cd1d-3a9eeaffc34a"
      },
      "source": [
        "transformers.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.11.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8UayK8nRiAp"
      },
      "source": [
        "in your working directory you will have to create 2 folders called \"model\" and  \"code\" as shown here : https://github.com/mobassir94/Deploy-trained-TensorFlow-2.x-models-using-Amazon-SageMaker/blob/main/jupyter.PNG\r\n",
        "\r\n",
        "![](https://github.com/mobassir94/Deploy-trained-TensorFlow-2.x-models-using-Amazon-SageMaker/blob/main/jupyter.PNG)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lzS9CiIVHHC"
      },
      "source": [
        "the model folder structure should be exactly like this : https://github.com/mobassir94/Deploy-trained-TensorFlow-2.x-models-using-Amazon-SageMaker/blob/main/folderstructure.PNG\r\n",
        "\r\n",
        "![](https://github.com/mobassir94/Deploy-trained-TensorFlow-2.x-models-using-Amazon-SageMaker/blob/main/folderstructure.PNG)\r\n",
        "\r\n",
        "my folder structure looks like this : https://github.com/mobassir94/Deploy-trained-TensorFlow-2.x-models-using-Amazon-SageMaker/blob/main/myfolderstructure.PNG\r\n",
        "\r\n",
        "![](https://github.com/mobassir94/Deploy-trained-TensorFlow-2.x-models-using-Amazon-SageMaker/blob/main/myfolderstructure.PNG)\r\n",
        "\r\n",
        "yours one should look similar (once you run similar code like the code below that fits your case)\r\n",
        "\r\n",
        "be careful, if the folder structure is not similar(like i showed above) then sagemaker won't find your model for making inference,,it costs me few hours"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgBDHrW7XhGB"
      },
      "source": [
        "my weight file was saved in .h5 format. my file name was \"model_checkpoint_0.h5\" and i uploaded that in s3 bucket, the code below downloads that weight file from s3 bucket and stores that file in my working directory,then i am loading my model and weight file into that model then finally after loading my weight file into my model i am converting it into tf servable format using this line of code : tf.saved_model.save(model, save_path)\r\n",
        "\r\n",
        "this is very important,\r\n",
        "see my save path is : save_path = os.path.join(\"/home/ec2-user/SageMaker/model/1/\")\r\n",
        "\r\n",
        "you can see inside model folder i have a folder called \"1\" which is basically my model's version and inside that \"1\" folder i am converting my weight file into tf servable format,after running the code below,my model folder looks like this : https://github.com/mobassir94/Deploy-trained-TensorFlow-2.x-models-using-Amazon-SageMaker/blob/main/myfolderstructure.PNG\r\n",
        "\r\n",
        "sagemaker expects model folder structure like that,if you make mistake then sagemaker won't find your model at all"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "mLfZ_d8GBvFo",
        "outputId": "7aadbef8-5583-4099-da2d-9805ab6d5cbe"
      },
      "source": [
        "''' \n",
        "modelpath = './model_checkpoint_0.h5'\n",
        "\n",
        "\n",
        "def regular_encode(texts, tokenizer, maxlen=512):\n",
        "    enc_di = tokenizer.batch_encode_plus(\n",
        "        texts, \n",
        "        return_attention_masks=False, \n",
        "        return_token_type_ids=False,\n",
        "        pad_to_max_length=True,\n",
        "        max_length=maxlen\n",
        "    )\n",
        "    \n",
        "    return np.array(enc_di['input_ids'])\n",
        "    \n",
        "\n",
        "#from keras_radam import RAdam\n",
        "def build_model(transformer, loss='binary_crossentropy', max_len=512):\n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    sequence_output = transformer(input_word_ids)[0]\n",
        "    cls_token = sequence_output[:, 0, :]\n",
        "    #x = tf.keras.layers.Dropout(0.3)(cls_token)\n",
        "    out = Dense(1, activation='sigmoid')(cls_token)\n",
        "    \n",
        "    \n",
        "    model = Model(inputs=input_word_ids, outputs=out)\n",
        "    #model.compile(RAdam( warmup_proportion=0.1, min_lr=1e-5), loss=loss, metrics=[tf.keras.metrics.AUC()])\n",
        "    \n",
        "    return model\n",
        "    \n",
        "    \n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "#from tokenizers import BertWordPieceTokenizer\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, Embedding\n",
        "from tensorflow.keras.layers import LSTM, GRU, Conv1D, SpatialDropout1D\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras import constraints\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.activations import *\n",
        "from tensorflow.keras.constraints import *\n",
        "from tensorflow.keras.initializers import *\n",
        "from tensorflow.keras.regularizers import *\n",
        "\n",
        "\n",
        "MODEL = 'jplu/tf-xlm-roberta-large'\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "maxlen = 192\n",
        "with strategy.scope():\n",
        "    transformer_layer = transformers.TFXLMRobertaModel.from_pretrained(MODEL)\n",
        "    model = build_model(transformer_layer, max_len=maxlen)\n",
        "model.summary()\n",
        "\n",
        "#https://stackoverflow.com/questions/61421528/read-h5-file-using-aws-boto3\n",
        "#https://stackoverflow.com/questions/29378763/how-to-save-s3-object-to-a-file-using-boto3\n",
        "\n",
        "import boto3\n",
        "import h5py\n",
        "s3_client = boto3.client('s3')\n",
        "\n",
        "s3_client.download_file('xlmroberta', 'model_checkpoint_0.h5', 'model_checkpoint_large.h5')\n",
        "\n",
        "#os.listdir('/home/ec2-user/SageMaker/')\n",
        "\n",
        "path = '/home/ec2-user/SageMaker/model_checkpoint_large.h5'\n",
        "model.load_weights(path)\n",
        "\n",
        "\n",
        "save_path = os.path.join(\"/home/ec2-user/SageMaker/model/1/\")\n",
        "tf.saved_model.save(model, save_path)\n",
        "\n",
        "'''"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' \\nmodelpath = \\'./model_checkpoint_0.h5\\'\\n\\n\\ndef regular_encode(texts, tokenizer, maxlen=512):\\n    enc_di = tokenizer.batch_encode_plus(\\n        texts, \\n        return_attention_masks=False, \\n        return_token_type_ids=False,\\n        pad_to_max_length=True,\\n        max_length=maxlen\\n    )\\n    \\n    return np.array(enc_di[\\'input_ids\\'])\\n    \\n\\n#from keras_radam import RAdam\\ndef build_model(transformer, loss=\\'binary_crossentropy\\', max_len=512):\\n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\\n    sequence_output = transformer(input_word_ids)[0]\\n    cls_token = sequence_output[:, 0, :]\\n    #x = tf.keras.layers.Dropout(0.3)(cls_token)\\n    out = Dense(1, activation=\\'sigmoid\\')(cls_token)\\n    \\n    \\n    model = Model(inputs=input_word_ids, outputs=out)\\n    #model.compile(RAdam( warmup_proportion=0.1, min_lr=1e-5), loss=loss, metrics=[tf.keras.metrics.AUC()])\\n    \\n    return model\\n    \\n    \\nstrategy = tf.distribute.MirroredStrategy()\\n\\n\\nfrom tensorflow.keras.callbacks import Callback\\nfrom sklearn.metrics import accuracy_score, roc_auc_score\\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\\n\\nfrom tensorflow.keras.models import Model\\n\\nfrom tensorflow.keras.optimizers import Adam\\n#from tokenizers import BertWordPieceTokenizer\\nfrom tensorflow.keras.layers import Dense, Input, Dropout, Embedding\\nfrom tensorflow.keras.layers import LSTM, GRU, Conv1D, SpatialDropout1D\\n\\nfrom tensorflow.keras import layers\\nfrom tensorflow.keras import optimizers\\nfrom tensorflow.keras import activations\\nfrom tensorflow.keras import constraints\\nfrom tensorflow.keras import initializers\\nfrom tensorflow.keras import regularizers\\n\\nimport tensorflow.keras.backend as K\\nfrom tensorflow.keras.layers import *\\nfrom tensorflow.keras.optimizers import *\\nfrom tensorflow.keras.activations import *\\nfrom tensorflow.keras.constraints import *\\nfrom tensorflow.keras.initializers import *\\nfrom tensorflow.keras.regularizers import *\\n\\n\\nMODEL = \\'jplu/tf-xlm-roberta-large\\'\\ntokenizer = AutoTokenizer.from_pretrained(MODEL)\\nmaxlen = 192\\nwith strategy.scope():\\n    transformer_layer = transformers.TFXLMRobertaModel.from_pretrained(MODEL)\\n    model = build_model(transformer_layer, max_len=maxlen)\\nmodel.summary()\\n\\n#https://stackoverflow.com/questions/61421528/read-h5-file-using-aws-boto3\\n#https://stackoverflow.com/questions/29378763/how-to-save-s3-object-to-a-file-using-boto3\\n\\nimport boto3\\nimport h5py\\ns3_client = boto3.client(\\'s3\\')\\n\\ns3_client.download_file(\\'xlmroberta\\', \\'model_checkpoint_0.h5\\', \\'model_checkpoint_large.h5\\')\\n\\n#os.listdir(\\'/home/ec2-user/SageMaker/\\')\\n\\npath = \\'/home/ec2-user/SageMaker/model_checkpoint_large.h5\\'\\nmodel.load_weights(path)\\n\\n\\nsave_path = os.path.join(\"/home/ec2-user/SageMaker/model/1/\")\\ntf.saved_model.save(model, save_path)\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3g2I73TZJKF"
      },
      "source": [
        "**we run the cell above for once,then we can comment out the cell because we have already converted our weight file into tf servable format and we don't have to do it over and over again,now inside our model folder we have converted weight file in tf servable format and now we don't need the cell above anymore, sagemaker will use our new converted tf servable format's model for making inference,now we can also delete our .h5 weight file from s3 bucket or from our working environment because we don't need that anymore**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoYcPyAaBvFp",
        "outputId": "ecbb2e57-3dfb-4f1d-b5df-02cf88d0bf3a"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPosl1XZBvFq",
        "outputId": "7a14d506-1453-4d87-d0b3-848ba9c0b4d7"
      },
      "source": [
        "!ls /home/ec2-user/SageMaker"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "basemodelDeployXLMrXLARGE.ipynb  code  lost+found  model\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibIdgTLKBvFq",
        "outputId": "a690d106-8b82-45ae-8012-ac414f74874f"
      },
      "source": [
        "os.listdir('/home/ec2-user/SageMaker/model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['xlmrlargewithcode.tar.gz', '1', '.ipynb_checkpoints']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVcNepI0aPcN"
      },
      "source": [
        "we will do cd to our model directory as we need to make tar of that folder and then will upload the tar.gz archive file containing Saved Model to S3 bucket.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROmbYe3hBvFq"
      },
      "source": [
        "cd /home/ec2-user/SageMaker/model/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvamGaAMBvFr",
        "outputId": "4e30bd62-bb30-409c-abc5-6ce2feb3b39d"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "basemodelDeployXLMrXLARGE.ipynb  \u001b[0m\u001b[01;34mcode\u001b[0m/  \u001b[01;34mlost+found\u001b[0m/  \u001b[01;34mmodel\u001b[0m/\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bznyKZMqBvFr",
        "outputId": "b471720f-3e4d-4d9c-b828-37c44ea20cf7"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/ec2-user/SageMaker\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuWnEfJbBvFs",
        "outputId": "59980173-f6a3-4b44-d3d8-f198f8434f09"
      },
      "source": [
        "os.listdir('/home/ec2-user/SageMaker/model/1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['assets', 'saved_model.pb', '.ipynb_checkpoints', 'variables']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dghNTXPJbPgM"
      },
      "source": [
        "i repeat, we need to make sure that after making tar our tar file contains folder structure like this : https://github.com/mobassir94/Deploy-trained-TensorFlow-2.x-models-using-Amazon-SageMaker/blob/main/myfolderstructure.PNG\r\n",
        "\r\n",
        "for example this tar command is wrong : !tar -C \"$PWD\" -czf xlmrbasemodel.tar.gz --absolute-names /home/ec2-user/SageMaker/model/\r\n",
        "\r\n",
        "it will break folder structure, the right command is : \r\n",
        "!tar -czvf xlmrlargewithcode.tar.gz 1/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cek-Jf-4BvFs",
        "outputId": "aeeea010-9a64-4655-9ace-a38f608e7c07"
      },
      "source": [
        "%%time\n",
        "#export_dir = '/home/ec2-user/SageMaker/model/1' \n",
        "\n",
        "#!tar -czvf xlmrbasemodel.tar.gz --absolute-names /home/ec2-user/SageMaker\n",
        "\n",
        "#!tar -C \"$PWD\" -czf xlmrmodel.tar.gz --absolute-names /home/ec2-user/SageMaker/model/\n",
        "\n",
        "#!tar -C \"$PWD\" -czf xlmrbasemodel.tar.gz --absolute-names /home/ec2-user/SageMaker/model/\n",
        "\n",
        "!tar -czvf xlmrlarge.tar.gz 1/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
            "Wall time: 7.63 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIcqQRwcBvFt",
        "outputId": "205d1ef8-ce7b-4936-b4bd-e69b7da51079"
      },
      "source": [
        "os.listdir('/home/ec2-user/SageMaker/model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['xlmrlargewithcode.tar.gz', '1', '.ipynb_checkpoints']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0cN6OLHBvFt"
      },
      "source": [
        "#!unzip /home/ec2-user/SageMaker/xlmrmodel.tar.gz\n",
        "\n",
        "#!tar -xf /home/ec2-user/SageMaker/xlmrmodel.tar.gz -C --absolute-names /home/ec2-user/SageMaker/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r1w2ue_btqm"
      },
      "source": [
        "model_data holds the s3 location of our tar.gz model file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGMmn7gSBvFt",
        "outputId": "6ee2f020-1f4b-45a0-f64d-2b8d67ff00ae"
      },
      "source": [
        "bucket_name = 'xlmroberta'\n",
        "model_data =  \"s3://xlmroberta/xlmrlarge/model/xlmrlarge.tar.gz\"\n",
        "\n",
        "#model_data = sess.upload_data(path='xlmrlarge.tar.gz', bucket=bucket_name, key_prefix = prefix+\"model\") #, key_prefix = prefix+\"model\"\n",
        "model_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'s3://xlmroberta/xlmrlarge/model/xlmrlarge.tar.gz'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA2b3yIxBvFu"
      },
      "source": [
        "cd /home/ec2-user/SageMaker/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCRJiiALc5CR"
      },
      "source": [
        "inside code directory we have 2 things: \r\n",
        "1. inference.py that contains your input,output handler and other things like tokenizer that can be used for making inference using your custom model,my inference.py looks like this(inside code folder) : https://github.com/mobassir94/Deploy-trained-TensorFlow-2.x-models-using-Amazon-SageMaker/blob/main/inference.py\r\n",
        "2. requirements.txt contains all the packages that needs to be installed for making inference using our model\r\n",
        "\r\n",
        "my code folder looks like this : https://github.com/mobassir94/Deploy-trained-TensorFlow-2.x-models-using-Amazon-SageMaker/blob/main/codefolder.PNG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ctujn4aBvFu",
        "outputId": "7a98b895-987a-412b-a1c2-3113476b032e"
      },
      "source": [
        "'''\n",
        "we are telling sagemaker to use inference.py file from code directory,it will automatically install requirements.txt file and also we are \n",
        "providing it the model xlmrlarge.tar.gz file that can be found inside our s3 bucket and in this location \"s3://xlmroberta/xlmrlarge/model/xlmrlarge.tar.gz\"\n",
        "yours location can be different\n",
        "'''\n",
        "model = Model(entry_point=\"inference.py\",\n",
        "              source_dir=\"code\",\n",
        "              model_data=model_data,\n",
        "              name=name_from_base(\"xlmrlarge\"),\n",
        "              role=role,\n",
        "              framework_version = '2.2.0'\n",
        "             )\n",
        "''' \n",
        "model = Model(\n",
        "              model_data=model_data,\n",
        "              name=name_from_base(\"xlmrlarge\"),\n",
        "              role=role,\n",
        "              framework_version = '2.2.0'\n",
        "             )\n",
        "\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The class sagemaker.tensorflow.serving.Model has been renamed in sagemaker>=2.\n",
            "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \\nmodel = Model(\\n              model_data=model_data,\\n              name=name_from_base(\"xlmrlarge\"),\\n              role=role,\\n              framework_version = \\'2.2.0\\'\\n             )\\n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_5pk4ayhuGO"
      },
      "source": [
        "the cell below will deploy our model using sagemaker and create endpoint,note that instance_type='ml.t2.xlarge' is the type of my notebook instance that i created from aws notebook instance section,yours one can be different here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqn2DZHHBvFv",
        "outputId": "b4e0c5ff-e528-4251-a87a-3f1049f798f8"
      },
      "source": [
        "%%time\n",
        "predictor = model.deploy(initial_instance_count=1,   instance_type='ml.t2.xlarge')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "update_endpoint is a no-op in sagemaker>=2.\n",
            "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "---------------!CPU times: user 8min 39s, sys: 14.2 s, total: 8min 53s\n",
            "Wall time: 16min 3s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCQBRGSgBvFw",
        "outputId": "d99531ff-98fc-45ff-845b-954dabaff441"
      },
      "source": [
        "inputs = \"ঢাকা বিমানবন্দরে ২৫০ কেজি'র বোমা: এটি কীভাবে এলো, বিস্ফোরিত হয়নি কেন\"\n",
        "#inputs2 = test.Words[:5].tolist()\n",
        "ck=json.dumps(inputs)\n",
        "ck"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"\\\\u09a2\\\\u09be\\\\u0995\\\\u09be \\\\u09ac\\\\u09bf\\\\u09ae\\\\u09be\\\\u09a8\\\\u09ac\\\\u09a8\\\\u09cd\\\\u09a6\\\\u09b0\\\\u09c7 \\\\u09e8\\\\u09eb\\\\u09e6 \\\\u0995\\\\u09c7\\\\u099c\\\\u09bf\\'\\\\u09b0 \\\\u09ac\\\\u09cb\\\\u09ae\\\\u09be: \\\\u098f\\\\u099f\\\\u09bf \\\\u0995\\\\u09c0\\\\u09ad\\\\u09be\\\\u09ac\\\\u09c7 \\\\u098f\\\\u09b2\\\\u09cb, \\\\u09ac\\\\u09bf\\\\u09b8\\\\u09cd\\\\u09ab\\\\u09cb\\\\u09b0\\\\u09bf\\\\u09a4 \\\\u09b9\\\\u09af\\\\u09bc\\\\u09a8\\\\u09bf \\\\u0995\\\\u09c7\\\\u09a8\"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeOivtEeidtb"
      },
      "source": [
        "for sanity check,the code cell below sends our input string to our deploymed model and from there using our inference.py script it returning us a predicted answer that gets stored in response variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFwcz2K8BvFw"
      },
      "source": [
        "response = predictor.predict(json.dumps(inputs))\n",
        "#response = predictor.predict(x_test1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yUeND-UBvFx",
        "outputId": "db3cd0fa-553f-414f-d067-8c4a35c786a2"
      },
      "source": [
        "print(response)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'predictions': 'Negative'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx0Ond45BvFx",
        "outputId": "721d1e8f-a092-4ebf-d80e-e22a601d90ac"
      },
      "source": [
        "response['predictions']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XxNsRnFBvFy",
        "outputId": "c7a69dd5-54c4-4374-baaa-22a03c9c7e6b"
      },
      "source": [
        "predictor.endpoint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The endpoint attribute has been renamed in sagemaker>=2.\n",
            "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xlmrlarge-2020-12-20-14-17-25-925'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcRzRoNJn31v"
      },
      "source": [
        "That's it, we have deployed our model,created endpoint,made inference using single sentence and got predicted answer as well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbIsB21wBvFy",
        "outputId": "e4c0a523-8322-4a18-f4ad-9bff5dc2d1ed"
      },
      "source": [
        "endpoint_name = predictor.endpoint\n",
        "\n",
        "endpoint_name"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The endpoint attribute has been renamed in sagemaker>=2.\n",
            "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xlmrlarge-2020-12-20-14-17-25-925'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLMaW3-rntcO"
      },
      "source": [
        "now we will see how we can invoke sagemaker endpoint from lambda or Integrate Lambda with Sagemaker, you can follow the instructions of this tutorial : https://www.youtube.com/watch?v=-iU36P8hizs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_P9cPq-n83W"
      },
      "source": [
        "you need to design lambda_handler according to the updated \"inference.py\" file or updated input,output handler that you gonna use to solve your data problem\r\n",
        "\r\n",
        "my lambda function looks like this :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJZ_csAeBvFz"
      },
      "source": [
        "\r\n",
        "import os\r\n",
        "import io\r\n",
        "import boto3\r\n",
        "import json\r\n",
        "import csv\r\n",
        "\r\n",
        "# grab environment variables\r\n",
        "ENDPOINT_NAME = 'your endpoint name'\r\n",
        "\r\n",
        "runtime= boto3.client('runtime.sagemaker', \r\n",
        "                     region_name='us-east-1', # make sure to set correct region\r\n",
        "                     aws_access_key_id='your aws access key', \r\n",
        "                      # These you get from AWS, for your account\r\n",
        "                      aws_secret_access_key='your aws secret key')\r\n",
        "\r\n",
        "def lambda_handler(event, context):\r\n",
        "    print(\"Received event: \" + json.dumps(event, indent=2))\r\n",
        "    \r\n",
        "    data = json.loads(json.dumps(event))\r\n",
        "    payload = data['data']\r\n",
        "    print(payload)\r\n",
        "    \r\n",
        "    response = runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME,\r\n",
        "                                       ContentType='application/json',\r\n",
        "                                       Body=payload)\r\n",
        "    print(response)\r\n",
        "    result = json.loads(response['Body'].read().decode())\r\n",
        "    print(result)\r\n",
        "    predicted_label = result['predictions']\r\n",
        "    \r\n",
        "    return predicted_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81bkTV7aoDcW"
      },
      "source": [
        "so once,we have this lambda,to really expose it,we need to put an API gateway infront of it,you can create new api by following this tutorial : https://www.youtube.com/watch?v=-iU36P8hizs\r\n",
        "\r\n",
        "once done,you will get invoke URL that you can use from postman to make post request. you can see here : https://github.com/mobassir94/Deploy-trained-TensorFlow-2.x-models-using-Amazon-SageMaker/blob/main/postmandemo.PNG that for the romanic bangla sentence \"ansary vhai khub valo manush\" in english which means \"ansary bhai is a very good man\" we get positive sentiment as a result which is appropriate for the sample we used for making prediction using our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lHIJHldqAAi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}